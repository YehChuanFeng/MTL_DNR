{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c80068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from scipy.stats import chi2_contingency\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df= pd.read_csv(f'C:/Users/M1107171/MIMIC/清出來的資料/DNR/20240326/full_step2.csv')\n",
    "#df = pd.read_csv(f'C:/Users/M1107171/MIMIC/清出來的資料/DNR/20240424/full_step2.csv')\n",
    "#df = pd.read_csv(f'C:/Users/M1107171/MIMIC/清出來的資料/DNR/20240616/full_step2.csv')\n",
    "\n",
    "#df = pd.read_csv(f'C:/Users/USER/M1326168/MIMIC/DNR/20250312/full_step2.csv')\n",
    "df = pd.read_csv(f'C:/Users/USER/M1326168/MIMIC/DNR/20241002/full_step2.csv')\n",
    "\n",
    "\n",
    "#df = pd.read_csv(f'C:/Users/USER/M1326168/MIMIC/DNR/20241002/test_30007565.csv')\n",
    "#df = df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa353aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994e61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['ICU_Class_2'].sum())\n",
    "\n",
    "#print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a95b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    assert df[col].isnull().values.any() == False,f'{col}欄位有缺失值'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b358c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "輸入label\n",
    "回傳正、負樣本索引\n",
    "\"\"\"\n",
    "def search_positive_negative_sample(y_list):\n",
    "    #正負樣本\n",
    "    positive_index = [i for i, arr in enumerate(y_list) if arr[0] == 1]\n",
    "    negative_index = [i for i, arr in enumerate(y_list) if arr[0] == 0]\n",
    "    \n",
    "    \n",
    "    # positive_count = len(positive_index)\n",
    "    # negative_count = len(negative_index)\n",
    "    \n",
    "    # print(f\"正樣本數量: {positive_count}\")\n",
    "    # print(f\"負樣本數量: {negative_count}\")   \n",
    "    #print(f\"正樣{head(10).positive_idex}\")\n",
    "\n",
    "    \n",
    "    #有正樣本情況下，只保留前面樣本\n",
    "    min_positive_index = min(positive_index) if positive_index else float('inf')\n",
    "    negative_index = [i for i in negative_index if i < min_positive_index]\n",
    "    return positive_index, negative_index\n",
    "\n",
    "\n",
    "# for i in range(0, len(positive_index)):\n",
    "#         i=i+1\n",
    "# print(\"Value: \", i)\n",
    "\"\"\"\n",
    "移除部分樣本\n",
    ">> 樣本數<=2  ->  全保留\n",
    ">> 反之，正樣本全保留，負樣本只保留部分\n",
    "\"\"\"\n",
    "def remove_sample(x_list, y_list, task_name = 'Null'):\n",
    "    assert len(x_list) == len(y_list)      \n",
    "    if len(x_list) <=2:\n",
    "        return x_list,y_list\n",
    "    else:\n",
    "        positive_index, negative_index = search_positive_negative_sample(y_list)\n",
    "        if task_name == 'DNR' or 'dialysis':\n",
    "            select_index = positive_index + random.sample(negative_index, k=min(1, len(negative_index)))          \n",
    "        else:\n",
    "            select_index = positive_index + random.sample(negative_index, k=min(2, len(negative_index)))\n",
    "        random.shuffle(select_index)                             \n",
    "                                                      \n",
    "        return [x_list[i] for i in select_index], [y_list[i] for i in select_index] \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed14034",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3天內發生DNR都視為DNR\n",
    "\"\"\"\n",
    "def correction_DNR(df_P):\n",
    "    df_P['max_DNR_old'] = df_P['DNR_old'].rolling(window=3, min_periods=1).max()\n",
    "    df_P['DNR'] = np.where(df_P['max_DNR_old'] == 1, 1, 0)\n",
    "    df_P.drop(columns='DNR_old', inplace=True)\n",
    "    df_P.drop(columns='max_DNR_old', inplace=True)\n",
    "    return df_P\n",
    "\n",
    "\"\"\"\n",
    ">>將第一天時序特徵擴充為每日靜態特徵\n",
    "\n",
    "extend_col_num: 前幾個col要擴充成新的靜態特徵\n",
    "\"\"\"\n",
    "def add_fisrt_day_columns(df_P, extend_col_num = 2):\n",
    "    # 創建新的欄位名稱列表\n",
    "    day_columns = [f\"first_day_{df_P.columns[i]}\" for i in range(extend_col_num)] \n",
    "\n",
    "    # 提取前兩個欄位的資料作為新的欄位值\n",
    "    df_first_day = pd.DataFrame([df_P.iloc[0, :extend_col_num].values], columns=day_columns) \n",
    "    df_first_day = pd.concat([df_first_day] * len(df_P), ignore_index=True)\n",
    "    # 將新的欄位新增到每一行後面\n",
    "    df_P = pd.concat([df_P, df_first_day], axis=1).reset_index(drop=True)\n",
    "    return df_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5577ffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_columns = pd.DataFrame()\n",
    "\n",
    "print(df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "928de9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "輸入患者資料、時窗大小 ==> 返回各任務的input、label\n",
    "\"\"\"\n",
    "def get_input_and_label(df_patient, window_size, stay_id):\n",
    "    \n",
    "    #宣告輸出格式\n",
    "    # input_features = { \n",
    "    #     'dod': [],'dod_3day': [],'dod_7day':[], 'dod_30day': [], 'dod_60day': [], 'dod_90day': [],'DNR':[], 'SBT':[], 'Weaning_successful':[]   \n",
    "    # }\n",
    "    # labels = {\n",
    "    #     'dod': [],'dod_3day': [],'dod_7day':[], 'dod_30day': [], 'dod_60day': [], 'dod_90day': [],'DNR':[], 'SBT':[], 'Weaning_successful':[]\n",
    "    # }\n",
    "\n",
    "    #宣告輸出格式\n",
    "    input_features = { \n",
    "        'dod': [],'dod_3day': [],'dod_7day':[], 'dod_30day': [], 'dod_60day': [], 'dod_90day': [],'DNR':[], 'SBT':[], 'Weaning_successful':[], \n",
    "        'dialysis': [],'InvasiveVent': [],'Vasopressor':[],'DNR':[]  \n",
    "    }\n",
    "    labels = {\n",
    "        'dod': [],'dod_3day': [],'dod_7day':[], 'dod_30day': [], 'dod_60day': [], 'dod_90day': [],'DNR':[], 'SBT':[], 'Weaning_successful':[], \n",
    "        'dialysis': [],'InvasiveVent': [],'Vasopressor':[],'DNR':[]\n",
    "    }\n",
    "\n",
    "\n",
    "    \n",
    "#     input_features = { \n",
    "#         'dialysis': [],'InvasiveVent': [],'Vasopressor':[],'DNR':[]\n",
    "#     }\n",
    "#     labels = {\n",
    "#         'dialysis': [],'InvasiveVent': [],'Vasopressor':[],'DNR':[]\n",
    "#     }\n",
    "    \n",
    "    if len(df_patient) <= window_size:\n",
    "        return input_features, labels\n",
    "    \n",
    "    #不當輸入的欄位\n",
    "    excluded_columns = list(input_features.keys())\n",
    "    excluded_columns = excluded_columns + ['InvasiveVent', 'tracheostomy', 'NonInvasiveVent', 'SupplementalOxygen', 'HFNC']\n",
    "    excluded_columns = excluded_columns + ['date','use_vent','Weaning','sofa','Reintubation','stay_id','dnr','first_day_date']\n",
    "    excluded_columns = excluded_columns + ['first_day_stay_id', 'first_day_use_vent', 'first_day_dod', 'first_day_dod_3day',\n",
    "                                           'first_day_dod_7day', 'first_day_dod_30day', 'first_day_dod_60day', 'first_day_dod_90day', \n",
    "                                           'first_day_InvasiveVent', 'first_day_tracheostomy', 'first_day_NonInvasiveVent', 'first_day_SupplementalOxygen','first_day_SBT']      \n",
    "    \n",
    "    for i in range(0, len(df_patient)):\n",
    "        if i + window_size >= len(df_patient):\n",
    "            break\n",
    "        \n",
    "        #判斷該時窗是否皆使用呼吸器\n",
    "        input_using_vent = df_patient['use_vent'][i:i + window_size].min() == 1\n",
    "        \n",
    "        df_input = df_patient.iloc[i:i + window_size, ~df_patient.columns.isin(excluded_columns)]\n",
    "        #df_input = df_input.astype(float)\n",
    "        input_X = df_input.values\n",
    "\n",
    "        global df_columns\n",
    "        if len(df_columns.columns) == 0:\n",
    "            df_columns = df_input.copy()\n",
    "\n",
    "        # labels_y = {\n",
    "        #     'dod': df_patient.iloc[i + window_size:i + window_size + 1]['dod'].values,\n",
    "        #     'dod_3day': df_patient.iloc[i + window_size:i + window_size + 1]['dod_3day'].values,\n",
    "        #     'dod_7day': df_patient.iloc[i + window_size:i + window_size + 1]['dod_7day'].values,\n",
    "        #     'dod_30day': df_patient.iloc[i + window_size:i + window_size + 1]['dod_30day'].values,\n",
    "        #     'dod_60day': df_patient.iloc[i + window_size:i + window_size + 1]['dod_60day'].values,\n",
    "        #     'dod_90day': df_patient.iloc[i + window_size:i + window_size + 1]['dod_90day'].values,\n",
    "        #     #'dialysis': df_patient.iloc[i + window_size:i + window_size + 1]['dialysis'].values,\n",
    "        #     'DNR': df_patient.iloc[i + window_size:i + window_size + 1]['DNR'].values,\n",
    "        #     'SBT': df_patient.iloc[i + window_size:i + window_size + 1]['SBT'].values,\n",
    "        #     'Weaning_successful': df_patient.iloc[i + window_size:i + window_size + 1]['Weaning_successful'].values,\n",
    "        # }\n",
    "\n",
    "        labels_y = {\n",
    "            'dod': df_patient.iloc[i + window_size:i + window_size + 1]['dod'].values,\n",
    "            'dod_3day': df_patient.iloc[i + window_size:i + window_size + 1]['dod_3day'].values,\n",
    "            'dod_7day': df_patient.iloc[i + window_size:i + window_size + 1]['dod_7day'].values,\n",
    "            'dod_30day': df_patient.iloc[i + window_size:i + window_size + 1]['dod_30day'].values,\n",
    "            'dod_60day': df_patient.iloc[i + window_size:i + window_size + 1]['dod_60day'].values,\n",
    "            'dod_90day': df_patient.iloc[i + window_size:i + window_size + 1]['dod_90day'].values,\n",
    "            #'dialysis': df_patient.iloc[i + window_size:i + window_size + 1]['dialysis'].values,\n",
    "            'DNR': df_patient.iloc[i + window_size:i + window_size + 1]['DNR'].values,\n",
    "            'SBT': df_patient.iloc[i + window_size:i + window_size + 1]['SBT'].values,\n",
    "            'Weaning_successful': df_patient.iloc[i + window_size:i + window_size + 1]['Weaning_successful'].values,\n",
    "            'dialysis': df_patient.iloc[i + window_size:i + window_size + 1]['dialysis'].values,\n",
    "            'InvasiveVent': df_patient.iloc[i + window_size:i + window_size + 1]['InvasiveVent'].values,\n",
    "            'Vasopressor' : df_patient.iloc[i + window_size:i + window_size + 1]['Vasopressor' ].values,\n",
    "            'DNR': df_patient.iloc[i + window_size:i + window_size + 1]['DNR'].values,\n",
    "        }\n",
    "\n",
    "   \n",
    "#         labels_y = {\n",
    "#             'dialysis': df_patient.iloc[i + window_size:i + window_size + 1]['dialysis'].values,\n",
    "#             'InvasiveVent': df_patient.iloc[i + window_size:i + window_size + 1]['InvasiveVent'].values,\n",
    "#             'Vasopressor' : df_patient.iloc[i + window_size:i + window_size + 1]['Vasopressor' ].values,\n",
    "#             'DNR': df_patient.iloc[i + window_size:i + window_size + 1]['DNR'].values,\n",
    "#         }\n",
    "        \n",
    "        # 輸入資料沒有使用呼吸器的處理 => 將標籤設置為-1\n",
    "        if input_using_vent == False:\n",
    "            for key in ['Weaning_successful', 'SBT']:\n",
    "                labels_y[key] = -1\n",
    "        \n",
    "        # 只保留標籤為1、0的樣本\n",
    "        for key in input_features.keys():\n",
    "            #assert labels_y[key] == 1 or labels_y[key] == 0\n",
    "            if labels_y[key] == 1 or labels_y[key] == 0:\n",
    "                input_features[key].append(input_X)\n",
    "                labels[key].append(labels_y[key])\n",
    "    \n",
    "    #remove sample\n",
    "    for key in input_features.keys():\n",
    "        x_list = input_features[key]\n",
    "        y_list = labels[key]\n",
    "        x_list_select, y_list_select = remove_sample(x_list,y_list,key)\n",
    "        input_features[key] = x_list_select\n",
    "        labels[key] = y_list_select\n",
    "        \n",
    "    return input_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "030c70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task_name_list = ['dod','dod_3day','dod_7day','dod_30day','dod_60day','dod_90day','DNR','Weaning_successful','SBT']\n",
    "#task_name_list = ['dialysis','InvasiveVent','Vasopressor','DNR']\n",
    "task_name_list = ['dod','dod_3day','dod_7day','dod_30day','dod_60day','dod_90day','DNR','Weaning_successful','SBT','dialysis','InvasiveVent','Vasopressor','DNR']\n",
    "\n",
    "\n",
    "input_features_list = []\n",
    "labels_list = []\n",
    "window_size = 3\n",
    "distinct_stay_id = df['stay_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab24707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 724/724 [00:06<00:00, 107.82it/s]\n"
     ]
    }
   ],
   "source": [
    "for stay_ids in tqdm(distinct_stay_id): \n",
    "    df_P = df[df['stay_id'] == stay_ids]\n",
    "\n",
    "    df_P = df_P.reset_index(drop=True)\n",
    "    df_P = correction_DNR(df_P)\n",
    "    df_P = add_fisrt_day_columns(df_P, extend_col_num = 103)\n",
    "    assert df_P.isna().any().any() == False, 'df_P中有缺失值'\n",
    "    \n",
    "    input_features, labels = get_input_and_label(df_P, window_size, stay_ids)\n",
    "    input_features_list.append(input_features)\n",
    "    labels_list.append(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84fbddfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 724/724 [00:00<00:00, 94014.74it/s]\n"
     ]
    }
   ],
   "source": [
    "task_samples = {}\n",
    "task_labels = {}\n",
    "\n",
    "for i in tqdm(range(len(input_features_list))): \n",
    "    x_dict = input_features_list[i]\n",
    "    y_dict = labels_list[i]\n",
    "    \n",
    "    for task, data in x_dict.items():\n",
    "        if task not in task_samples:\n",
    "            task_samples[task] = []\n",
    "        task_samples[task] = task_samples[task] + data\n",
    "        \n",
    "    for task, label in y_dict.items():\n",
    "        if task not in task_labels:\n",
    "            task_labels[task] = []\n",
    "        task_labels[task] = task_labels[task] + label        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b55c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name in task_name_list:\n",
    "    task_samples[task_name] = np.array(task_samples[task_name])\n",
    "    task_labels[task_name] = np.squeeze(task_labels[task_name])\n",
    "    #print(task_samples[task_name].shape)\n",
    "    \n",
    "# print(len(task_samples[task_name]))\n",
    "# print(task_samples[task_name])\n",
    "# print(task_name)\n",
    "# print(task_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6918298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_label_distribution (data_Y):\n",
    "    count_1 = np.count_nonzero(data_Y == 1)\n",
    "    count_0 = np.count_nonzero(data_Y == 0)\n",
    "    count_others = np.count_nonzero((data_Y != 1) & (data_Y != 0))\n",
    "    #print(f'count1:{count_1}....{count_0}')\n",
    "    ratio_1 = round(count_1/len(data_Y)*100,2)\n",
    "    ratio_0 = round(count_0/len(data_Y)*100,2)\n",
    "    ratio_others = round(count_others/len(data_Y)*100,2)\n",
    "    print(f'1=>{count_1}({ratio_1}%),  0=>{count_0}({ratio_0}%),  others=>{count_others}({ratio_others}%)')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc020de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "-----dod-------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13904\\672849220.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mfeature_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_of_sample\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_of_sample\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "date = datetime.today().strftime('%y%m%d')\n",
    "#route = './data/sample' \n",
    "\n",
    "route = 'C:/Users/USER/M1326168/MIMIC/DNR/20241002/data/sample' \n",
    "#route = 'C:/Users/USER/M1326168/MIMIC/DNR/20250312/data/sample' \n",
    "\n",
    "\n",
    "    \n",
    "is_save = input('save? (y/n)')\n",
    "if is_save == 'y':\n",
    "    for task_name in task_name_list:\n",
    "        print(f'---------------\\n-----{task_name}-------')\n",
    "        for data_type in ['train','validation','test']:\n",
    "            len_of_sample = len(task_samples[task_name])\n",
    "            feature_count = int(len(df_columns.columns)/2)\n",
    "            if data_type == 'train':\n",
    "                x = task_samples[task_name][:int(len_of_sample*0.8),:,:]\n",
    "                y = task_labels[task_name][:int(len_of_sample*0.8)]\n",
    "            elif data_type == 'validation':\n",
    "                x = task_samples[task_name][int(len_of_sample*0.8):int(len_of_sample*0.9),:,:]\n",
    "                y = task_labels[task_name][int(len_of_sample*0.8):int(len_of_sample*0.9)]\n",
    "            else:\n",
    "                x = task_samples[task_name][int(len_of_sample*0.9):,:,:]\n",
    "                y = task_labels[task_name][int(len_of_sample*0.9):]\n",
    "            assert x.shape[0] == y.shape[0],f'輸入、輸出樣本數不一致 => {x.shape[0]}!={y.shape[0]}'\n",
    "            assert np.any(np.isnan(x)) == False\n",
    "            assert np.any(np.isnan(y)) == False\n",
    "            #print(f'{task_name}...{data_type}...{x.shape}')\n",
    "            check_label_distribution(y)\n",
    "            np.save(f'{route}/{data_type}_X_{task_name}.npy', x)\n",
    "            np.save(f'{route}/{data_type}_Y_{task_name}.npy', y)\n",
    "        \n",
    "    print('Saved successfully....', date)\n",
    "    \n",
    "print(\"Finish....\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_columns.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_label_distribution(task_labels['DNR'][:])\n",
    "#check_label_distribution(task_labels['Full code'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de492310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_columns.iloc[:,:].to_csv(f\"./data/sample/full_feature_name.csv\", index=False)\n",
    "df_columns.iloc[:,:].to_csv(f\"C:/Users/USER/M1326168/MIMIC/DNR/20241002/data/sample/full_feature_name.csv\", index=False)\n",
    "#df_columns.iloc[:,:].to_csv(f\"C:/Users/USER/M1326168/MIMIC/DNR/20250312/data/sample/full_feature_name.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181397d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da9a5b1",
   "metadata": {},
   "source": [
    "# 用來處理特徵所屬category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f2f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_columns = pd.read_csv(\"./data/sample/full_feature_name.csv\")\n",
    "\n",
    "df_columns = pd.read_csv(\"C:/Users/USER/M1326168/MIMIC/DNR/20241002/data/sample/full_feature_name.csv\")\n",
    "\n",
    "#df_columns = pd.read_csv(\"C:/Users/USER/M1326168/MIMIC/DNR/20250312/data/sample/full_feature_name.csv\")\n",
    "print(len(df_columns.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_with_category = pd.DataFrame({'feature_name': df_columns.columns})\n",
    "df_col_with_category['category'] = \"Can't find\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義函數來根據條件設置新欄位的值\n",
    "def set_type(row):\n",
    "    respiratory = [\n",
    "        'FiO2', 'Minute Ventilation', 'Mean Airway Pressure', 'Peak Airway Pressure', 'PEEP', 'Plateau', 'use_vent_acc','use_vent_consecutive_7days',           \n",
    "        'Tidal Volume', 'Respiratory Rate','Consecutive_avg_FiO2_Over50', 'Consecutive_avg_FiO2_Over60', 'use_vent_over3','first_day_use_vent_over3 '\n",
    "    ] \n",
    "    \n",
    "    GCS = [\n",
    "        'Maintain GCS >= 8', 'RASS'\n",
    "    ]\n",
    "    target = [\n",
    "        'Anxiety', 'Assess for anxiety, depression, or delirium which may contribut', 'Asystole', 'Blood Transfusion','dialysis_over3', 'dialysis_over7', \n",
    "        'Consult to pastoral care, social services, palliative care, psy', 'Early mobilization', 'Encourage family to participate in care', \n",
    "        'Encourage patient / family members to accept individual reponse', 'Encourage patient / family to set and verbalize care goals', \n",
    "        'Enlist family support / family sitters', 'Explanation', 'Family at bedside', 'Family Called', 'Family Conference', 'Family Member', \n",
    "        'Family Talked to MD', 'Family Talked to RN', 'Family Visited', 'Full code', 'Full resistance', 'Fully awake', \n",
    "        'Listen attentively when patient attempts to communicate', 'Liver Failure', \"Manage environment for patient''s maximum comfort\", \n",
    "        'Maintain GCS >= 8', 'No Proxy', 'No, not sedated', 'Palliative Care', 'Patient / family involved in treatment plan', \n",
    "        'Patient / family will have adequate support once CMO decision h', 'Patient / family will have support throughout the dying process', \n",
    "        'Patient / family will participate in planning and initiating cu', 'Patient refused', 'Patient Verbalized', 'Promote early mobility', \n",
    "        'Rehab', 'Rehabilitation', 'Social Service Involved', 'Social Services', 'Social Work', 'Spiritual', 'Thermoregulation', 'TPN', 'Tracheostomy', \n",
    "        'Tracheostomy tube', 'With family', 'With spouse', 'Withdraws','Spouse','Strength L Arm', 'Strength L Leg', 'Strength R Arm', 'Strength R Leg', \n",
    "        'Response', 'Coping/Knowledge Deficit  NCP - Expected outcomes',  'HFNC','Full_code_interval','Strength Arm','Strength Leg',\n",
    "        'Muscle', 'Vocalization', 'Body Movements', 'Facial Expressions', 'CPOT(SUM)','ICU_Class_1','ICU_Class_2','ICU_Class_3','CVICU'\n",
    "        ,\n",
    "    ]\n",
    "    #'DNR_after_in_ICU_day', 'early_DNR'目前不使用\n",
    "    sofa = [\n",
    "        'coagulation', 'liver', 'cardiovascular', 'cns', 'renal', 'respiration',\n",
    "        'SOFA-coagulation', 'SOFA-liver', 'SOFA-cardiovascular', 'SOFA-cns', 'SOFA-renal', 'SOFA-respiration',\n",
    "    ]\n",
    "    patient = [\n",
    "        'gender', 'age', 'race', 'apsiii'\n",
    "    ]\n",
    "    intakeoutput = [\n",
    "        'total', 'Fluid_intake_value', 'Nutrition_Enteral_value', 'Urine_value'\n",
    "    ]\n",
    "    infusiondrug = [\n",
    "        'Vasopressor', 'Relaxant', 'Sedation', 'PPI', 'Pain control', 'antibiotic','Consecutive_Vasopressor_Over3', 'Consecutive_Vasopressor_Over7'\n",
    "    ]\n",
    "    microlab = [\n",
    "        'Aspergillus', 'Candida', 'Abdomen', 'Blood', 'Respiratory tract', 'Skin and soft tissue', 'Urinary tract', 'Others'\n",
    "    ]\n",
    "    diagnosis = [\n",
    "        'MI', 'CHF', 'PVD', 'CVD', 'Dementia', 'CPD', 'RD', 'PUD', 'MLD', 'DM_acute', 'DM_Chronic', 'Hemiplegia', 'Renal', \n",
    "        'Malignancy', 'LD', 'MST', 'AIDS','dialysis','dialysis_since_last_event','dialysis_acc'\n",
    "    ]\n",
    "    vital_sign = [\n",
    "        'SaO2', 'Heart Rate', 'Systemic Systolic', 'Systemic Diastolic', 'Systemic Mean'\n",
    "    ]\n",
    "    lab = [\n",
    "        'Platelets x1000', 'WBC x1000', 'Hgb', 'PO2', 'PaCO2', 'Glucose', 'BUN', 'pH', 'Sodium', 'Potassium', 'Magnesium', \n",
    "        'Calcium', 'Chloride', 'creatinine', 'HCO3', 'Phosphate', 'PT-INR', 'Troponin - T', 'Ferritin', 'Transferrin', 'CRP', \n",
    "        'Fibrinogen', 'HDL', 'LDL', 'Total Cholesterol', 'Direct Bilirubin', 'Lactate', 'LDH', 'Lipase', 'Amylase', 'CPK', 'CPK-MB', \n",
    "        'BNP', 'PTT', 'Fe', 'TIBC', 'Fe/TIBC Ratio', 'Serum_Osmolality', 'TSH', 'T3', 'T4', 'Free T4', 'Ionized Calcium', 'Triglycerides', \n",
    "        'Cortisol', 'Uric Acid', 'Ammonia', 'Vitamin B12'\n",
    "    ]\n",
    "    \n",
    "    cate_dict = {\n",
    "        \"respiratory\":respiratory,\n",
    "        \"target\":target, \n",
    "        \"sofa\":sofa, \n",
    "        \"patient\":patient, \n",
    "        \"intakeoutput\":intakeoutput, \n",
    "        \"infusiondrug\":infusiondrug, \n",
    "        \"microlab\":microlab, \n",
    "        \"diagnosis\":diagnosis, \n",
    "        \"vital_sign\":vital_sign, \n",
    "        \"lab\":lab,\n",
    "        \"GCS\": GCS\n",
    "    }\n",
    "    \n",
    "    for key, current_list in cate_dict.items():\n",
    "        if row['feature_name'] in current_list:\n",
    "            return key\n",
    "        \n",
    "        first_day_current_list = [f\"first_day_{name}\" for name in current_list]\n",
    "        if row['feature_name'] in first_day_current_list:\n",
    "            return key\n",
    "    return \"Can't find\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b381b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 幫每個特徵設置所屬category\n",
    "df_col_with_category['category'] = df_col_with_category.apply(set_type, axis=1)\n",
    "print(df_col_with_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d88bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#檢測是否有找不到的category => 不能有\n",
    "filtered_df = df_col_with_category[df_col_with_category['category'] == \"Can't find\"]\n",
    "print(filtered_df)\n",
    "print(filtered_df['feature_name'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77936a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#時序:114  靜態:256-114=142\n",
    "if len(filtered_df) != 0:\n",
    "    #df_col_with_category.to_csv(f\"./data/sample/full_feature_name_with_category.csv\", index=False)\n",
    "    \n",
    "    df_col_with_category.to_csv(f\"C:/Users/USER/M1326168/MIMIC/DNR/20241002/data/sample/full_feature_name_with_category.csv\", index=False)\n",
    "    \n",
    "    #df_col_with_category.to_csv(f\"C:/Users/USER/M1326168/MIMIC/DNR/20250312/data/sample/full_feature_name_with_category.csv\", index=False)\n",
    "    print(\"儲存成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b1a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
